{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Google Colab\uc5d0\uc11c \ub178\ud2b8\ubd81\uc744 \uc2e4\ud589\ud558\uc2e4 \ub54c\uc5d0\ub294 \n# https://tutorials.pytorch.kr/beginner/colab \ub97c \ucc38\uace0\ud558\uc138\uc694.\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TorchMultimodal \ud29c\ud1a0\ub9ac\uc5bc: FLAVA \ubbf8\uc138\uc870\uc815\n========================================\n\n**\ubc88\uc5ed:** [\uae40\ucc2c](https://github.com/chanmuzi)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uba40\ud2f0 \ubaa8\ub2ec AI\ub294 \ucd5c\uadfc\uc5d0 \uc774\ubbf8\uc9c0 \uc790\ub9c9\ucd94\uac00, \uc2dc\uac01\uc801 \uac80\uc0c9\ubd80\ud130 \ud14d\uc2a4\ud2b8\ub85c\ubd80\ud130\n\uc774\ubbf8\uc9c0\ub97c \uc0dd\uc131\uac19\uc740 \ucd5c\uadfc\uc758 \uc751\uc6a9\uae4c\uc9c0 \uadf8 \uc0ac\uc6a9\uc774 \ube60\ub974\uac8c \ud655\uc0b0\ub418\uace0 \uc788\uc2b5\ub2c8\ub2e4.\n**TorchMultimodal\uc740 PyTorch\ub97c \uae30\ubc18\uc73c\ub85c \ud558\ub294 \ub77c\uc774\ube0c\ub7ec\ub9ac\ub85c, \uba40\ud2f0 \ubaa8\ub2ec\n\uc5f0\uad6c\ub97c \uac00\ub2a5\ud558\uac8c \ud558\uace0 \uac00\uc18d\ud654\ud558\uae30 \uc704\ud55c \ube4c\ub529 \ube14\ub85d\uacfc end-to-end \uc608\uc81c\ub4e4\uc744\n\uc81c\uacf5\ud569\ub2c8\ub2e4**.\n\n\ubcf8 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c\ub294 **\uc0ac\uc804 \ud6c8\ub828\ub41c SoTA \ubaa8\ub378\uc778**\n[FLAVA](https://arxiv.org/pdf/2112.04482.pdf) **\ub97c** **TorchMultimodal\n\ub77c\uc774\ube0c\ub7ec\ub9ac\uc5d0\uc11c \uc0ac\uc6a9\ud558\uc5ec \uba40\ud2f0 \ubaa8\ub2ec \uc791\uc5c5\uc778 \uc2dc\uac01\uc801 \uc9c8\uc758 \uc751\ub2f5(VQA)\uc5d0\n\ubbf8\uc138\uc870\uc815\ud558\ub294 \ubc29\ubc95\uc744 \ubcf4\uc5ec \ub4dc\ub9ac\uaca0\uc2b5\ub2c8\ub2e4.** \uc774 \ubaa8\ub378\uc740 \ud14d\uc2a4\ud2b8\uc640 \uc774\ubbf8\uc9c0\ub97c\n\uc704\ud55c \ub450 \uac1c\uc758 \ub2e8\uc77c \ubaa8\ub2ec \ud2b8\ub79c\uc2a4\ud3ec\uba38 \uae30\ubc18 \uc778\ucf54\ub354\uc640 \ub450 \uc784\ubca0\ub529\uc744 \uacb0\ud569\ud558\ub294\n\ub2e4\uc911 \ubaa8\ub2ec \uc778\ucf54\ub354\ub85c \uad6c\uc131\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uc774 \ubaa8\ub378\uc740 \ub300\uc870\uc801, \uc774\ubbf8\uc9c0-\ud14d\uc2a4\ud2b8\n\ub9e4\uce6d, \uadf8\ub9ac\uace0 \ud14d\uc2a4\ud2b8, \uc774\ubbf8\uc9c0 \ubc0f \ub2e4\uc911 \ubaa8\ub2ec \ub9c8\uc2a4\ud0b9 \uc190\uc2e4\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc0ac\uc804\n\ud6c8\ub828\ub418\uc5c8\uc2b5\ub2c8\ub2e4.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc124\uce58\n====\n\n\uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc744 \uc704\ud574\uc11c\ub294 TextVQA \ub370\uc774\ud130\uc14b\uacfc Hugging Face\uc758\n`bert \ud1a0\ud06c\ub098\uc774\uc800` \ub97c \uc0ac\uc6a9\ud560 \uac83\uc785\ub2c8\ub2e4. \ub530\ub77c\uc11c TorchMultimodal \uc678\uc5d0\ub3c4\ndatasets\uacfc transformers\ub97c \uc124\uce58\ud574\uc57c \ud569\ub2c8\ub2e4.\n\n```{=html}\n<div style=\"background-color: #54c7ec; color: #fff; font-weight: 700; padding-left: 10px; padding-top: 5px; padding-bottom: 5px\"><strong>NOTE:</strong></div>\n```\n```{=html}\n<div style=\"background-color: #f3f4f7; padding-left: 10px; padding-top: 10px; padding-bottom: 10px; padding-right: 10px\">\n```\n```{=html}\n<p>\uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc744 Google Colab\uc5d0\uc11c \uc2e4\ud589\ud560 \uacbd\uc6b0, \uc0c8\ub85c\uc6b4 \uc140\uc744 \ub9cc\ub4e4\uace0 \ub2e4\uc74c\uc758 \uba85\ub839\uc5b4\ub97c \uc2e4\ud589\ud558\uc5ec\ud544\uc694\ud55c \ud328\ud0a4\uc9c0\ub97c \uc124\uce58\ud558\uc138\uc694:<pre><code>!pip install torchmultimodal-nightly\n!pip install datasets\n!pip install transformers</code></pre></p>\n```\n```{=html}\n</div>\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub2e8\uacc4\n====\n\n1.  \ub2e4\uc74c \uba85\ub839\uc5b4\ub97c \uc2e4\ud589\ud558\uc5ec Hugging Face \ub370\uc774\ud130\uc14b\uc744 \ucef4\ud4e8\ud130\uc758 \ub514\ub809\ud1a0\ub9ac\uc5d0\n    \ub2e4\uc6b4\ub85c\ub4dc\ud558\uc138\uc694:\n\n    ``` {.}\n    wget http://dl.fbaipublicfiles.com/pythia/data/vocab.tar.gz \n    tar xf vocab.tar.gz\n    ```\n\n    ```{=html}\n    <div style=\"background-color: #54c7ec; color: #fff; font-weight: 700; padding-left: 10px; padding-top: 5px; padding-bottom: 5px\"><strong>NOTE:</strong></div>\n    ```\n    ```{=html}\n    <div style=\"background-color: #f3f4f7; padding-left: 10px; padding-top: 10px; padding-bottom: 10px; padding-right: 10px\">\n    ```\n    ```{=html}\n    <p>\uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc744 Google Colab\uc5d0\uc11c \uc2e4\ud589\ud558\ub294 \uacbd\uc6b0, \uc0c8 \uc140\uc5d0\uc11c \uc774 \uba85\ub839\uc5b4\ub97c \uc2e4\ud589\ud558\uace0 \uba85\ub839\uc5b4 \uc55e\uc5d0 \ub290\ub08c\ud45c (!)\ub97c \ubd99\uc774\uc138\uc694.</p>\n    ```\n    ```{=html}\n    </div>\n    ```\n\n2.  \ubcf8 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c\ub294 VQA\ub97c \uc774\ubbf8\uc9c0\uc640 \uc9c8\ubb38(\ud14d\uc2a4\ud2b8)\uc774 \uc785\ub825\ub418\uace0 \ucd9c\ub825\uc774 \ub2f5\ubcc0\n    \ud074\ub798\uc2a4\uc778 \ubd84\ub958 \uc791\uc5c5\uc73c\ub85c \ucde8\uae09\ud569\ub2c8\ub2e4. \ub530\ub77c\uc11c \ub2f5\ubcc0 \ud074\ub798\uc2a4\uc640 \ub808\uc774\ube14\n    \ub9e4\ud551\uc744 \uc0dd\uc131\ud560 \ub2e8\uc5b4\uc7a5 \ud30c\uc77c\uc744 \ub2e4\uc6b4\ub85c\ub4dc\ud574\uc57c \ud569\ub2c8\ub2e4.\n\n    \ub610\ud55c Hugging Face\uc5d0\uc11c [textvqa\n    \ub370\uc774\ud130\uc14b](https://arxiv.org/pdf/1904.08920.pdf) \uc744 \ubd88\ub7ec\uc624\ub294\ub370, \uc774\n    \ub370\uc774\ud130\uc14b\uc740 34602\uac1c\uc758 \ud6c8\ub828 \uc0d8\ud50c(\uc774\ubbf8\uc9c0, \uc9c8\ubb38, \ub2f5\ubcc0)\uc744 \ud3ec\ud568\ud558\uace0\n    \uc788\uc2b5\ub2c8\ub2e4.\n\n3997\uac1c\uc758 \ub2f5\ubcc0 \ud074\ub798\uc2a4\uac00 \uc788\uc74c\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc73c\uba70, \uc774\uc5d0\ub294 \uc54c \uc218 \uc5c6\ub294 \ub2f5\ubcc0\uc744\n\ub098\ud0c0\ub0b4\ub294 \ud074\ub798\uc2a4\ub3c4 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "with open(\"data/vocabs/answers_textvqa_more_than_1.txt\") as f:\n  vocab = f.readlines()\n\nanswer_to_idx = {}\nfor idx, entry in enumerate(vocab):\n  answer_to_idx[entry.strip(\"\\n\")] = idx\nprint(len(vocab))\nprint(vocab[:5])\n\nfrom datasets import load_dataset\ndataset = load_dataset(\"facebook/textvqa\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub370\uc774\ud130\uc14b\uc5d0\uc11c \uc0d8\ud50c \uc5d4\ud2b8\ub9ac\ub97c \ud45c\uc2dc\ud574 \ubd05\uc2dc\ub2e4:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np \nidx = 5 \nprint(\"Question: \", dataset[\"train\"][idx][\"question\"]) \nprint(\"Answers: \" ,dataset[\"train\"][idx][\"answers\"])\nim = np.asarray(dataset[\"train\"][idx][\"image\"].resize((500,500)))\nplt.imshow(im)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3\\. \ub2e4\uc74c\uc73c\ub85c, \uc774\ubbf8\uc9c0\uc640 \ud14d\uc2a4\ud2b8\ub97c \ubaa8\ub378\uc5d0\uc11c \uc0ac\uc6a9\ud560 \uc218 \uc788\ub294 \ud150\uc11c\ub85c \ubcc0\ud658\ud558\uae30\n\uc704\ud55c \ubcc0\ud658 \ud568\uc218\ub97c \uc791\uc131\ud569\ub2c8\ub2e4. - \uc774\ubbf8\uc9c0\uc758 \uacbd\uc6b0, torchvision\uc758 \ubcc0\ud658\uc744\n\uc0ac\uc6a9\ud558\uc5ec \ud150\uc11c\ub85c \ubcc0\ud658\ud558\uace0 \uc77c\uc815\ud55c \ud06c\uae30\ub85c \uc870\uc815\ud569\ub2c8\ub2e4. - \ud14d\uc2a4\ud2b8\uc758 \uacbd\uc6b0,\nHugging Face\uc758 `BertTokenizer` \ub97c \uc0ac\uc6a9\ud558\uc5ec \ud1a0\ud070\ud654(\ubc0f \ud328\ub529)\ud569\ub2c8\ub2e4. -\n\ub2f5\ubcc0(\uc989, \ub808\uc774\ube14)\uc758 \uacbd\uc6b0, \uac00\uc7a5 \ube48\ubc88\ud558\uac8c \ub098\ud0c0\ub098\ub294 \ub2f5\ubcc0\uc744 \ud6c8\ub828 \ub808\uc774\ube14\ub85c\n\uc0ac\uc6a9\ud569\ub2c8\ub2e4:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nfrom torchvision import transforms\nfrom collections import defaultdict\nfrom transformers import BertTokenizer\nfrom functools import partial\n\ndef transform(tokenizer, input):\n  batch = {}\n  image_transform = transforms.Compose([transforms.ToTensor(), transforms.Resize([224,224])])\n  image = image_transform(input[\"image\"][0].convert(\"RGB\"))\n  batch[\"image\"] = [image]\n\n  tokenized=tokenizer(input[\"question\"],return_tensors='pt',padding=\"max_length\",max_length=512)\n  batch.update(tokenized)\n\n\n  ans_to_count = defaultdict(int)\n  for ans in input[\"answers\"][0]:\n    ans_to_count[ans] += 1\n  max_value = max(ans_to_count, key=ans_to_count.get)\n  ans_idx = answer_to_idx.get(max_value,0)\n  batch[\"answers\"] = torch.as_tensor([ans_idx])\n  return batch\n\ntokenizer=BertTokenizer.from_pretrained(\"bert-base-uncased\",padding=\"max_length\",max_length=512)\ntransform=partial(transform,tokenizer)\ndataset.set_transform(transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4\\. \ub9c8\uc9c0\ub9c9\uc73c\ub85c, `torchmultimodal` \uc5d0\uc11c `flava_model_for_classification`\n\uc744 \uac00\uc838\uc635\ub2c8\ub2e4. \uc774\uac83\uc740 \uae30\ubcf8\uc801\uc73c\ub85c \uc0ac\uc804 \ud6c8\ub828\ub41c FLAVA \uccb4\ud06c\ud3ec\uc778\ud2b8\ub97c \ub85c\ub4dc\ud558\uace0\n\ubd84\ub958 \ud5e4\ub4dc\ub97c \ud3ec\ud568\ud569\ub2c8\ub2e4.\n\n\ubaa8\ub378\uc758 \uc21c\ubc29\ud5a5 \ud568\uc218\ub294 \uc774\ubbf8\uc9c0\ub97c \uc2dc\uac01 \uc778\ucf54\ub354\uc5d0 \ud1b5\uacfc\uc2dc\ud0a4\uace0 \uc9c8\ubb38\uc744 \ud14d\uc2a4\ud2b8\n\uc778\ucf54\ub354\uc5d0 \ud1b5\uacfc\uc2dc\ud0b5\ub2c8\ub2e4. \uc774\ubbf8\uc9c0\uc640 \uc9c8\ubb38\uc758 \uc784\ubca0\ub529\uc740 \uadf8 \ud6c4 \uba40\ud2f0 \ubaa8\ub2ec \uc778\ucf54\ub354\ub97c\n\ud1b5\uacfc\ud569\ub2c8\ub2e4. \ucd5c\uc885 \uc784\ubca0\ub529\uc740 CLS \ud1a0\ud070\uc5d0 \ud574\ub2f9\ud558\uba70, \uc774\ub294 MLP \ud5e4\ub4dc\ub97c \ud1b5\uacfc\ud558\uc5ec\n\uac01 \uac00\ub2a5\ud55c \ub2f5\ubcc0\uc5d0 \ub300\ud55c \ud655\ub960 \ubd84\ud3ec\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torchmultimodal.models.flava.model import flava_model_for_classification\nmodel = flava_model_for_classification(num_classes=len(vocab))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5\\. \ub370\uc774\ud130\uc14b\uacfc \ubaa8\ub378\uc744 \ud568\uaed8 \ubaa8\uc544 3\ud68c \ubc18\ubcf5\uc744 \uc704\ud55c \uac04\ub2e8\ud55c \ud6c8\ub828 \ub8e8\ud504\ub97c\n\uc791\uc131\ud558\uc5ec \ubaa8\ub378 \ud6c8\ub828 \ubc29\ubc95\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torch import nn\nBATCH_SIZE = 2\nMAX_STEPS = 3\nfrom torch.utils.data import DataLoader\n\ntrain_dataloader = DataLoader(dataset[\"train\"], batch_size= BATCH_SIZE)\noptimizer = torch.optim.AdamW(model.parameters())\n\n\nepochs = 1\nfor _ in range(epochs):\n  for idx, batch in enumerate(train_dataloader):\n    optimizer.zero_grad()\n    out = model(text = batch[\"input_ids\"], image = batch[\"image\"], labels = batch[\"answers\"])\n    loss = out.loss\n    loss.backward()\n    optimizer.step()\n    print(f\"Loss at step {idx} = {loss}\")\n    if idx >= MAX_STEPS-1:\n      break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uacb0\ub860\n====\n\n\uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c\ub294 TorchMultimodal\uc758 FLAVA\ub97c \uc0ac\uc6a9\ud558\uc5ec \uba40\ud2f0 \ubaa8\ub2ec \uc791\uc5c5\uc5d0\n\ubbf8\uc138 \uc870\uc815\ud558\ub294 \uae30\ubcf8\uc801\uc778 \ubc29\uc2dd\uc744 \uc18c\uac1c\ud588\uc2b5\ub2c8\ub2e4. \uac1d\uccb4 \ud0d0\uc9c0\ub97c \uc704\ud55c \uba40\ud2f0 \ubaa8\ub2ec\n\ubaa8\ub378\uc778\n[MDETR](https://github.com/facebookresearch/multimodal/tree/main/torchmultimodal/models/mdetr)\n\uacfc \uc774\ubbf8\uc9c0, \ube44\ub514\uc624, 3D \ubd84\ub958\ub97c \ud3ec\uad04\ud558\ub294 \ub2e4\uc791\uc5c5 \ubaa8\ub378\n[Omnivore](https://github.com/facebookresearch/multimodal/blob/main/torchmultimodal/models/omnivore.py)\n\uac19\uc740 \ub77c\uc774\ube0c\ub7ec\ub9ac\uc758 \ub2e4\ub978 \uc608\uc81c\ub4e4\ub3c4 \ud655\uc778\ud574 \ubcf4\uc138\uc694.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}